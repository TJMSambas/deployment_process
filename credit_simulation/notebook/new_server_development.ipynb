{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:02:37.528500Z",
     "start_time": "2019-11-20T15:37:32.161000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:53: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "127.0.0.1 - - [20/Nov/2019 22:37:40] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Create API of ML model using flask\n",
    "\n",
    "'''\n",
    "This code takes the JSON data while POST request an performs the prediction using loaded model and returns\n",
    "the results in JSON format.\n",
    "'''\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the model\n",
    "model = pickle.load(open('LogReg.pkl','rb'))\n",
    "\n",
    "# Load the scaler & encoder\n",
    "scaler = pickle.load(open('scaler.pkl','rb'))\n",
    "encoder = pickle.load(open('encoder.pkl','rb'))\n",
    "\n",
    "@app.route('/api',methods=['POST'])\n",
    "def predict():\n",
    "    # Get the data from the POST request.\n",
    "    data = request.get_json(force = True)\n",
    "    \n",
    "    # ---------------DEVELOPER ZONE---------------------\n",
    "    # Defining parameter\n",
    "    include_categorical = False\n",
    "    num_predictors = ['present_res_since',\n",
    "                     'duration_in_month',\n",
    "                     'credits_this_bank',\n",
    "                     'installment_as_income_perc',\n",
    "                     'credit_amount',\n",
    "                     'people_under_maintenance',\n",
    "                     'age']\n",
    "    if include_categorical:\n",
    "        cat_predictors = ['savings',\n",
    "                         'foreign_worker',\n",
    "                         'credit_history',\n",
    "                         'present_emp_since',\n",
    "                         'job',\n",
    "                         'purpose',\n",
    "                         'personal_status_sex',\n",
    "                         'property',\n",
    "                         'other_debtors',\n",
    "                         'telephone',\n",
    "                         'account_check_status',\n",
    "                         'other_installment_plans',\n",
    "                         'housing']\n",
    "    \n",
    "    # Data preprocessing\n",
    "    df = pd.DataFrame.from_dict(data, orient = 'index')\n",
    "    df_numerical = scaler.transform(df[num_predictors])\n",
    "    if include_categorical:\n",
    "        df_categorical = encoder.transform(df[cat_predictors]).toarray()\n",
    "        data_input = np.concatenate((df_numerical, df_categorical), axis = 1)\n",
    "    else:\n",
    "        data_input = df_numerical\n",
    "    # ---------------(END) DEVELOPER ZONE---------------------\n",
    "    \n",
    "    # Make prediction using model loaded from disk as per the data.\n",
    "    prediction = model.predict(data_input)\n",
    "\n",
    "    # Take the first value of prediction\n",
    "    output = prediction.tolist()\n",
    "    return jsonify(output)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        app.run(port=5000, debug=None)\n",
    "    except:\n",
    "        print(\"Server is exited unexpectedly. Please contact server admin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg Using Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-21T03:53:45.457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [21/Nov/2019 10:53:49] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Nov/2019 10:54:02] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Nov/2019 10:54:06] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Create API of ML model using flask\n",
    "\n",
    "'''\n",
    "This code takes the JSON data while POST request an performs the prediction using loaded model and returns\n",
    "the results in JSON format.\n",
    "'''\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the model\n",
    "model = pickle.load(open('LogReg.pkl','rb'))\n",
    "\n",
    "# Load the scaler & encoder\n",
    "scaler = pickle.load(open('scaler.pkl','rb'))\n",
    "dict_encoder = pickle.load(open('label_dictionary.pkl','rb'))\n",
    "\n",
    "@app.route('/api',methods=['POST'])\n",
    "def predict():\n",
    "    # Get the data from the POST request.\n",
    "    data = request.get_json(force = True)\n",
    "    \n",
    "    # ---------------DEVELOPER ZONE---------------------\n",
    "    # Defining parameter\n",
    "    include_categorical = True\n",
    "    num_predictors = ['credit_amount',\n",
    "                     'installment_as_income_perc',\n",
    "                     'credits_this_bank',\n",
    "                     'present_res_since',\n",
    "                     'age',\n",
    "                     'people_under_maintenance',\n",
    "                     'duration_in_month']\n",
    "    if include_categorical:\n",
    "        cat_predictors = ['job',\n",
    "                         'present_emp_since',\n",
    "                         'other_installment_plans',\n",
    "                         'credit_history',\n",
    "                         'personal_status_sex',\n",
    "                         'foreign_worker',\n",
    "                         'other_debtors',\n",
    "                         'telephone',\n",
    "                         'savings',\n",
    "                         'property',\n",
    "                         'purpose',\n",
    "                         'account_check_status',\n",
    "                         'housing']\n",
    "    \n",
    "    # Data preprocessing\n",
    "    df = pd.DataFrame.from_dict(data, orient = 'index')\n",
    "    df_numerical = scaler.transform(df[num_predictors])\n",
    "    if include_categorical:\n",
    "        df_categorical = df[cat_predictors].apply(lambda x: dict_encoder[x.name].transform(x)).values\n",
    "        data_input = np.concatenate((df_numerical, df_categorical), axis = 1)\n",
    "    else:\n",
    "        data_input = df_numerical\n",
    "    # ---------------(END) DEVELOPER ZONE---------------------\n",
    "    \n",
    "    # Make prediction using model loaded from disk as per the data.\n",
    "    prediction = model.predict(data_input)\n",
    "\n",
    "    # Take the first value of prediction\n",
    "    output = prediction.tolist()\n",
    "    return jsonify(output)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        app.run(port=5000, debug=None)\n",
    "    except:\n",
    "        print(\"Server is exited unexpectedly. Please contact server admin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:51:05.630500Z",
     "start_time": "2019-11-20T16:14:29.255500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "127.0.0.1 - - [20/Nov/2019 23:14:33] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Create API of ML model using flask\n",
    "\n",
    "'''\n",
    "This code takes the JSON data while POST request an performs the prediction using loaded model and returns\n",
    "the results in JSON format.\n",
    "'''\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the model\n",
    "model = pickle.load(open('LGBM.pkl','rb')) # <------------------------DIFFERENCE IS HERE\n",
    "\n",
    "# Load the scaler & encoder\n",
    "scaler = pickle.load(open('scaler.pkl','rb'))\n",
    "encoder = pickle.load(open('label_encoder.pkl','rb')) # <------------------------DIFFERENCE IS HERE\n",
    "\n",
    "@app.route('/api',methods=['POST'])\n",
    "def predict():\n",
    "    # Get the data from the POST request.\n",
    "    data = request.get_json(force = True)\n",
    "    \n",
    "    # ---------------DEVELOPER ZONE---------------------\n",
    "    # Defining parameter\n",
    "    include_categorical = True\n",
    "    num_predictors = ['present_res_since',\n",
    "                     'duration_in_month',\n",
    "                     'credits_this_bank',\n",
    "                     'installment_as_income_perc',\n",
    "                     'credit_amount',\n",
    "                     'people_under_maintenance',\n",
    "                     'age']\n",
    "    if include_categorical:\n",
    "        cat_predictors = ['account_check_status',\n",
    "                         'job',\n",
    "                         'other_debtors',\n",
    "                         'foreign_worker',\n",
    "                         'credit_history',\n",
    "                         'telephone',\n",
    "                         'property',\n",
    "                         'other_installment_plans',\n",
    "                         'housing',\n",
    "                         'savings',\n",
    "                         'present_emp_since',\n",
    "                         'purpose',\n",
    "                         'personal_status_sex']\n",
    "    \n",
    "    # Data preprocessing\n",
    "    df = pd.DataFrame.from_dict(data, orient = 'index')\n",
    "    df_numerical = scaler.transform(df[num_predictors])\n",
    "    if include_categorical:\n",
    "        df_categorical = df[cat_predictors]\n",
    "        for col in cat_predictors:\n",
    "            df_categorical[col] = encoder.fit_transform(df_categorical[col])\n",
    "        df_categorical = df_categorical.values\n",
    "        data_input = np.concatenate((df_numerical, df_categorical), axis = 1)\n",
    "    else:\n",
    "        data_input = df_numerical\n",
    "    # ---------------(END) DEVELOPER ZONE---------------------\n",
    "    \n",
    "    # Make prediction using model loaded from disk as per the data.\n",
    "    prediction = model.predict(data_input)\n",
    "    prediction = prediction > 0.5\n",
    "    prediction = prediction.astype(int)\n",
    "    \n",
    "    # Take the first value of prediction\n",
    "    output = prediction.tolist()\n",
    "    return jsonify(output)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        app.run(port=5000, debug=None)\n",
    "    except:\n",
    "        print(\"Server is exited unexpectedly. Please contact server admin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Using Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-20T17:18:30.889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [21/Nov/2019 00:18:39] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Nov/2019 00:23:55] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Create API of ML model using flask\n",
    "\n",
    "'''\n",
    "This code takes the JSON data while POST request an performs the prediction using loaded model and returns\n",
    "the results in JSON format.\n",
    "'''\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the model\n",
    "model = pickle.load(open('LGBM_new.pkl','rb'))\n",
    "\n",
    "# Load the scaler & encoder\n",
    "scaler = pickle.load(open('scaler.pkl','rb'))\n",
    "dict_encoder = pickle.load(open('label_dictionary.pkl','rb'))\n",
    "\n",
    "@app.route('/api',methods=['POST'])\n",
    "def predict():\n",
    "    # Get the data from the POST request.\n",
    "    data = request.get_json(force = True)\n",
    "    \n",
    "    # ---------------DEVELOPER ZONE---------------------\n",
    "    # Defining parameter\n",
    "    include_categorical = True\n",
    "    num_predictors = ['present_res_since',\n",
    "                     'duration_in_month',\n",
    "                     'credits_this_bank',\n",
    "                     'installment_as_income_perc',\n",
    "                     'credit_amount',\n",
    "                     'people_under_maintenance',\n",
    "                     'age']\n",
    "    if include_categorical:\n",
    "        cat_predictors = ['account_check_status',\n",
    "                         'job',\n",
    "                         'other_debtors',\n",
    "                         'foreign_worker',\n",
    "                         'credit_history',\n",
    "                         'telephone',\n",
    "                         'property',\n",
    "                         'other_installment_plans',\n",
    "                         'housing',\n",
    "                         'savings',\n",
    "                         'present_emp_since',\n",
    "                         'purpose',\n",
    "                         'personal_status_sex']\n",
    "    \n",
    "    # Data preprocessing\n",
    "    df = pd.DataFrame.from_dict(data, orient = 'index')\n",
    "    df_numerical = scaler.transform(df[num_predictors])\n",
    "    if include_categorical:\n",
    "        df_categorical = df[cat_predictors].apply(lambda x: dict_encoder[x.name].transform(x)).values\n",
    "        data_input = np.concatenate((df_numerical, df_categorical), axis = 1)\n",
    "    else:\n",
    "        data_input = df_numerical\n",
    "    # ---------------(END) DEVELOPER ZONE---------------------\n",
    "    \n",
    "    # Make prediction using model loaded from disk as per the data.\n",
    "    prediction = model.predict(data_input)\n",
    "\n",
    "    # Take the first value of prediction\n",
    "    output = prediction.tolist()\n",
    "    return jsonify(output)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        app.run(port=5000, debug=None)\n",
    "    except:\n",
    "        print(\"Server is exited unexpectedly. Please contact server admin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
